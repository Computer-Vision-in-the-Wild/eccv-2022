<!DOCTYPE html>
<html lang="en">

<head>
    <meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
    <!--Open Graph Related Stuff-->
    <meta property="og:title" content="Workshop on Computer Vision in the Wild 2022" />
    <meta property="og:url" content="https://computer-vision-in-the-wild.github.io/eccv-2022/" />
    <meta property="og:description" content="October 23 at ECCV 2022" />
    <meta property="og:description" content="ECCV 2022" />
    <meta property="og:site_name" content="Computer Vision in the Wild 2022" />
    <meta property="og:image" content="https://computer-vision-in-the-wild.github.io/eccv-2022/static/img/eccv_2022_cvinwild_header.png" />
    <meta property="og:image:url" content="https://computer-vision-in-the-wild.github.io/eccv-2022/static/img/eccv_2022_cvinwild_header.png" />
    <meta name="twitter:card" content="summary_large_image">
    <meta name="twitter:title" content="Workshop on Computer Vision in the Wild 2022">
    <meta name="twitter:description" content="October 23 at ECCV 2022">
    <meta name="twitter:description" content="ECCV 2022">
    <meta name="twitter:image" content="https://computer-vision-in-the-wild.github.io/eccv-2022/static/img/eccv_2022_cvinwild_header.png">
    <title>Computer Vision in the Wild</title>
    <link rel="stylesheet" href="./static/css/foundation.css">
    <link rel="stylesheet" href="./static/css/main.css">
    <script src="./static/js/vendor/jquery.js"></script>
    <script src="./static/js/jquery-2.1.3.min.js"></script>

    <script type="text/javascript" src="./static/js/jquery.countdown.min.js"></script>
    <script type="text/javascript" src="./static/js/moment.min.js"></script>
    <script type="text/javascript" src="./static/js/moment-timezone-with-data.min.js"></script>

    <script type="text/javascript" src="./static/js/main-vqa.js"></script>
    <script type="text/javascript" src="./static/js/main-gqa.js"></script>
    <script type="text/javascript" src="./static/js/main-visdial.js"></script>
    <script type="text/javascript" src="./static/js/main-textvqa.js"></script>
    <script type="text/javascript" src="./static/js/main-textcaps.js"></script>
    <script type="text/javascript" src="./static/js/main-vizwiz.js"></script>

</head>
<style type="text/css">
.schedule table {
    -webkit-border-radius: 5px;
    -moz-border-radius: 5px;
    border-radius: 5px;
}

.schedule tr:hover {
    background-color: #D3D3D3;
}

.schedule img {
    max-height: 95px;
    max-width: 140px;
    margin-right: 2px;
    margin-top: 4px;
    margin-bottom: 4px;
    border-radius: 50%;
}
</style>

<body class="off-canvas hide-extras" style="min-width:1300px; min-height:750px;">
    <header>
        <div class="row">
            <a href="https://computer-vision-in-the-wild.github.io/eccv-2022"><img style="height: 200px; position:absolute; top:150px; left:26px;" src="./static/eccv2022/img/ECCV-logo3.png" alt="logo" /></a>
            <!-- <h1><img style="height: 200px;" src="./static/eccv2022/img/cvinthewild_logo.jpg" alt="logo" /><br></h1> -->
            <br>
        </div>
    </header>
    <div class="contain-to-grid">
        <!-- <nav class="top-bar" data-topbar> -->
            <!-- <section class="top-bar-section"> -->
                <!-- Right Nav Section -->
                <!-- <ul class="right"> -->
                    <!-- <li><a href="index.html">Home</a></li> -->
                    <!-- <li><a href="people.html">People</a></li> -->
                    <!-- <li><a href="code.html">Code</a></li> -->
                    <!-- <li><a href="http://vqa.cloudcv.org/" onClick="ga('send', 'event', { eventCategory: 'Outgoing Link', eventAction: 'Demo', eventLabel: 'Demo'});">Demo</a></li> -->
                    <!-- <li class="has-dropdown"><a href="download.html">Download</a> -->
                        <!-- <ul class="dropdown"> -->
                            <!-- <li><a href="download.html">VQA v2</a></li> -->
                            <!-- <li><a href="vqa_v1_download.html">VQA v1</a></li> -->
                        <!-- </ul> -->
                    <!-- </li> -->
                    <!-- <li><a href="evaluation.html">Evaluation</a></li>
                    <li class="has-dropdown"><a href="challenge.html">Challenge</a>
                        <ul class="dropdown">
                            <li><a href="challenge.html">2021</a></li>
                            <li><a href="challenge_2020.html">2020</a></li>
                            <li><a href="challenge_2019.html">2019</a></li>
                            <li><a href="challenge_2018.html">2018</a></li>
                            <li><a href="challenge_2017.html">2017</a></li>
                            <li><a href="challenge_2016.html">2016</a></li>
                        </ul>
                    </li> -->
                    <!-- <li class="has-dropdown"><a href="http://visualqa.org/vqa_v2_teaser.html">Browse</a>
                        <ul class="dropdown">
                            <li><a href="http://visualqa.org/vqa_v2_teaser.html">VQA v2</a></li>
                            <li><a href="https://vqabrowser.cloudcv.org/">VQA v1</a></li>

                        </ul>
                    </li> -->
                    <!-- <li><a href="http://visualqa.org/visualize/">Visualize</a></li> -->
                    <!-- <li class="active has-dropdown"><a href="workshop.html">Workshop</a>
                        <ul class="dropdown"> -->
                            <!-- <li><a href="workshop.html"></a></li> -->
                            <!-- <li><a href="workshop_2020.html">2020</a></li>
                            <li><a href="workshop_2019.html">2019</a></li>
                            <li><a href="workshop_2018.html">2018</a></li>
                            <li><a href="workshop_2017.html">2017</a></li>
                            <li><a href="workshop_2016.html">2016</a></li> -->
                        <!-- </ul> -->
                    <!-- </li> -->
                    <!-- <li><a href="sponsors.html">Sponsors</a></li> -->
                    <!-- <li><a href="terms.html">Terms</a></li> -->
                    <!-- <li><a href="external.html">External</a></li> -->
                <!-- </ul> -->
            </section>
        </nav>
    </div>
    <section role="main" style="padding: 1em;">
        <div class="row">
            <p style="font-size:50px; color:black; font-weight: 50" align=center>Workshop on Computer Vision in the Wild
                <br>
                <span style="font-size:30px; color:gray; font-weight: 50" align=center>@ ECCV 2022, October 23</span>
                <!-- <br> -->
                <!-- <br> -->
                <!-- <span style="font-size:20px; color:black; font-weight: 400" align=center>Zoom and Gatherly links on ECCV 2022 website: <a target="_blank" href="https://www.eventscribe.net/2021/2021CVPR/agenda.asp?startdate=6/19/2021&enddate=6/19/2021&BCFO=M&pfp=Workshops&mode=&tn=&cpftwo=&custwo=&pta=/">Link</a> <br> Navigate to: Workshops -> Sat, October 23 -> Search for "Computer Vision in the Wild" workshop entry</b></span> -->

            </p>

            <!-- <table width="100%">
                <tr>
                    <td width=150>
                        <center> <span style="color:gray;"><b>Ended</b></span> <br>
                            Recording: <a target="_blank" href="https://youtu.be/L-86t1AW3z4">[Video]</a> </center>
                    </td>
                    <td style="padding-left:8px"><b>Panel-1: Future Directions</b>
                      <br>Vittorio Ferrari, Damien Teney, Raquel Fern치ndez, Aida Nematzadeh, Olga Russakovsky
                      <br>Hosted on Zoom, joining link on the internal CVPR website
                    </td>
                    <td width=200>
                        Starts June 19, 9 AM PT!
                    </td>
                </tr>
                <tr>
                    <td width=150>
                        <center> <span style="color:gray;"><b>Ended</b></span></center>
                    </td>
                    <td style="padding-left:8px"><b>Live QA-1</b>
                      <br>Individual live QA for challenge related talks and poster spotlight presenters.
                      <br>Hosted on Gatherly, joining link on the internal CVPR website
                    </td>
                    <td width=200>
                        Starts June 19, 12 PM PT!
                    </td>
                </tr>
                <tr>
                    <td width=150>
                        <center> <span style="color:gray;"><b>Ended</b></span> <br>
                            Recording: <a target="_blank" href="https://youtu.be/GobqvKXCVtc">[Video]</a></center>
                    </td>
                    <td style="padding-left:8px"><b>Panel-2: Future Directions</b>
                      <br>Justin Johnson, He He, Mohit Bansal, Katerina Fragkiadaki, Anirudh Koul
                      <br>Hosted on Zoom, joining link on the internal CVPR website
                    </td>
                    <td width=200>
                        Starts June 19, 3 PM PT!
                    </td>
                </tr>
                <tr>
                    <td width=150>
                    </td>
                    <td style="padding-left:8px"><b>Live QA-2</b>
                        <br>Individual live QA for challenge related talks and poster spotlight presenters.
                        <br>Hosted on Gatherly, joining link on the internal CVPR website
                      </td>
                      <td width=200>
                          Starts June 20, 12 AM PT!
                      </td>
                </tr>
            </table>

            <p style="font-size:20px; color:black; font-weight: 50" align=center>
                <a href="workshop.html" style="padding:13px">Home</a>
                <a href="#program" style="padding:13px">Program</a>
                <a href="posters_2021.html" style="padding:13px">Poster Spotlights</a>
            </p>
            <hr>
            <div class="large-12 columns">
                <img src="./static/img/challenge.png" height="900" width="500" style="display:block; margin:auto;" frameBorder="0">
            </div>
        </div> -->
        <br>
        <br>

        <div class="row">
            <h1 style="font-size:30px; color:grey; font-weight: 200">Overview</h1>
            <div class="large-12 columns" style="text-align:left;">
                <p style="font-size:15px; font-weight: 400; text-align:left">
                State-of-the-art computer vision systems are trained to predict a fixed set of predetermined object categories. This restricted form of supervision limits their generality and usability since additional labeled data is needed to specify any other visual concept. 
                <br><br>
                Recent works show that learning from large-scale image-text data is a promising approach to building transferable visual models that can effortlessly adapt to a wide range of downstream computer vision (CV) and  multimodal (MM) tasks. For example, 
                <a href="https://openai.com/blog/clip/"> CLIP </a>, <a href="https://ai.googleblog.com/2021/05/align-scaling-up-visual-and-vision.html"> ALIGN </a> and <a href="https://arxiv.org/abs/2111.11432"> Florence </a>  for image classification,  
                <a href="https://arxiv.org/abs/2104.13921"> ViLD </a>, <a href="https://arxiv.org/abs/2112.09106"> RegionCLIP </a> and <a href="https://arxiv.org/abs/2112.03857"> GLIP </a> for object detection.  
                These vision models with language interface are naturally open-vocabulary recogntion models, showing superior zero-shot and few-shot adaption performance on various real-world scenarios. 
                <br><br>
                We propose this "Computer Vision in the Wild" workshop, aiming to gather academic and industry communities to work on CV problems in real-world scenarios, focusing on the challenge of open-set/domain visual recognition and efficient task-level transfer. 
                Since there is no established benchmarks to measure the progress of "CV in the Wild", we develop new benchmarks for image classification and object detection, to measure the task-level transfer ablity of various models/methods over diverse real-world datasets, in terms of both prediction accuracy and adaption efficiency. This workshop will also host two challenges based on the benchmarks.
                </p>
            </div>
        </div>
<!--  -->

<div class="row">
    <h1 style="font-size:30px; color:grey; font-weight: 200">Call for Papers</h1>
    <div class="large-12 columns" style="text-align:left;">
        <p style="font-size:15px; font-weight: 400; text-align:left">
            <ul style="font-size:15px;">
                Topics of interest include but are not limited to:
            
                <li style="margin-left:30px">
                    Open-set visual recognition methods, including classification, object detection, segmentation in images and videos
                </li>
                <li style="margin-left:30px">
                    Unified neural networks architecutres and training objectives over different CV & MM tasks
                </li>
                <li style="margin-left:30px">
                    Large-scale pre-training, with images/videos only, image/video-text pairs, and external knoweldge 
                </li>
                <li style="margin-left:30px">
                    Efficient large visual model adaptation methods, measured by #training samples (zero-shot and few-shot), #trainable parameter, throughput, training cost
                </li>                
                <li style="margin-left:30px">
                    New metrics / benchmarks / datasets to evaluate task-level transfer and open-domain visual recognition
                </li>            

                <br>
                We accept abstract submissions to our workshop. All submissions shall have maximally 8 pages (excluding references) following the ECCV 2022 author guidelines. All submissions will be reviewed by the Program Committee on the basis of technical quality, relevance to scope of the conference, originality, significance, and clarity.
                <br><br>
                Submission Portal: <a href="https://cmt3.research.microsoft.com/CVinW2022"> [CMT] </a>
                <br><br>
            </ul>    
        </p>
    </div>
</div>



                <!--  -->
                <div class="row">
                    <h1 style="font-size:30px; color:grey; font-weight: 200">CV in the Wild Challenges</h1>
                    <div class="large-12 columns" style="text-align:left;">
                        <p style="font-size:15px; font-weight: 400; text-align:left">          
                <!--  -->
                <ul style="font-size:15px;"> 
                There are two challenges associated with this workshop: "Image Classification in the Wild" (ICinW) and "Object Detection in the Wild" (ODinW). We summarize their evaluation datasets and metrics in the table below.<br><br>
                    <table width="80%">
                        <tr>
                            <td width=50>
                                <center> <span style="color:gray;"><b>Challenge</b></span> <br>
                                    <!-- Recording: <a target="_blank" href="https://youtu.be/L-86t1AW3z4">[Video]</a> </center> -->
                            </td>
                            <td width=100>
                                <center> <span style="color:gray;"><b>Eval Datasets</b></span> <br>
                            </td>
                            <td width=200>
                                <center> <span style="color:gray;"><b>Eval Metrics</b></span> <br>
                            </td>
                            <!-- <td width=150>
                                <center> <span style="color:gray;"><b>Pretraining data*</b></span> <br>
                            </td> -->
                        </tr>
                        <tr>
                            <td width=150>
                                <center> <span><b>ICinW</b></span></center>
                            </td>
                            <td width=150>
                                <center> <span><b>20 Image Classification Datasets</b></span></center>
                            </td>
                            <td width=150>
                                <center> <span><b>Averaged scores in zero, few, full-shot settings</b></span></center>
                            </td>
                            <!-- <td width=150>
                                <center> <span><b>ImageNet21k+CC15M</b></span></center>
                            </td> -->
                            <!-- <td style="padding-left:8px"><b>Live QA-1</b>
                            </td> -->
                            <!-- <td style="padding-left:8px"><b>Live QA-1</b>
                            </td>
                            <td width=200>
                                Starts June 19, 12 PM PT!
                            </td>
                            <td width=200>
                                Starts June 19, 9 AM PT!
                            </td> -->
                        </tr>
                        <tr>
                            <td width=150>
                                <center> <span><b>ODinW</b></span></center>
                            </td>
                            <td width=150>
                                <center> <span><b>35 Object Detection Datasets</b></span></center>
                            </td>
                            <td width=150>
                                <center> <span><b>Averaged scores in zero, few, full-shot settings</b></span></center>
                            </td>
                            <!-- <td width=150>
                                <center> <span><b>Objects365+CC15M</b></span></center>
                            </td> -->
                        </tr>
                        <!-- <tr>
                            <td width=150>
                            </td>
                            <td style="padding-left:8px"><b>Live QA-2</b>
                                <br>Individual live QA for challenge related talks and poster spotlight presenters.
                                <br>Hosted on Gatherly, joining link on the internal CVPR website
                              </td>
                              <td width=200>
                                  Starts June 20, 12 AM PT!
                              </td> -->
                        </tr>
                    </table>
                    
                   
                    To prevent a race purely in pre-training data and model size, we will have two tracks.
                    
                    
                    <li style="margin-left:30px">
                        For the academic track, pre-training data is limited to ImageNet21k, Objects365, CC15M, and YFCC15M
                    </li>
                    

                    <li style="margin-left:30px">
                        For the industry track, there is no limitation on pre-training data and model size. Teams are required to disclose meta info of model and data if extra data is used.
                    </li>

                    <br>
                    More information about the challenges are released: 
                    <a href="https://computer-vision-in-the-wild.github.io/ELEVATER/"> [Benchmark] </a>
                     <a href="https://arxiv.org/abs/2204.08790"> [Document] </a>.
                          Our evaluation server will be online at late July, 2022.
                    <br><br>

                </p>
            </div>
            <!-- <hr> -->
        </div>
<!--  -->

<!--  -->
        <div class="row">
            <h1 style="font-size:30px; color:grey; font-weight: 200">Dates</h1>
            <div class="large-12 columns" style="text-align:left;">
                <div class="large-12 columns" style="text-align:left;">
                    <p style="font-size:15px; font-weight: 200; border-style: solid;
                                  border-width: 1px; text-align:justify; padding:5px; width:65%">
                        <code>
                                <span style="width:40%; margin:5px; display:inline-block;">July 25, 2022</span>
                                <span style="display:inline-block; margin-left:10px;">Competition starts, testing phase begins</span><br>

                                <span style="width:40%; margin:5px; display:inline-block;">
                                    September 30, 2022
                                </span>
                                <span style="display:inline-block; margin-left:10px;">Competition ends (challenge paper submission)</span><br>

                                <span style="width:40%; margin:5px; display:inline-block;">September 30, 2022</span>
                                <span style="display:inline-block; margin-left:10px;">Workshop paper submission deadline</span><br>

                                <span style="width:40%; margin:5px; display:inline-block;">TBD</span>
                                <span style="display:inline-block; margin-left:10px;">Workshop paper acceptance decision to authors</span><br>

                            </code></p>
                </div>
            </div>
            <hr>
        </div>

        <div class="row">
            <h1 style="font-size:30px; color:grey; font-weight: 200">Invited Speakers (TBD)</h1>
            <!-- <div class="team" id="people">
                <div class="row">
                    <div class="large-1 columns" style="padding-left:0px">
                        <p></p>
                    </div>
                    <div class="large-2 columns">
                        <a target="_blank" href="https://staff.fnwi.uva.nl/r.fernandezrovira/"><img src="./static/invited/speakers_2021/raquel.png" class="home_team_picture" style="width:150px; height:150px;">
                            <br>
                            <p style="font-weight: 200;">Raquel Fern치ndez</a>
                        <br>University of Amsterdam</p>
                    </div>

                    <div class="large-2 columns">
                        <a target="_blank" href="https://sites.google.com/view/vittoferrari"><img src="./static/invited/speakers_2021/vittorio.png" class="home_team_picture" style="width:150px; height:150px;">
                            <br>
                            <p style="font-weight: 200;">Vittorio Ferrari</a>
                        <br>Google</p>
                    </div>

                    <div class="large-2 columns">
                        <a target="_blank" href="https://hhexiy.github.io/"><img src="./static/invited/speakers_2021/hehe.jpg" class="home_team_picture" style="width:150px; height:150px;">
                            <br>
                            <p style="font-weight: 200;">He He</a>
                        <br>New York University</p>
                    </div>

                    <div class="large-2 columns">
                        <a target="_blank" href="https://www.linkedin.com/in/anirudhkoul/"><img src="./static/invited/speakers_2021/anirudh.jpeg" class="home_team_picture" style="width:150px; height:150px;">
                            <br>
                            <p style="font-weight: 200;">Anirudh Koul</a>
                        <br>Pinterest</p>
                    </div>

                    <div class="large-2 columns">
                        <a target="_blank" href="https://www.cs.princeton.edu/~olgarus/"><img src="./static/invited/speakers_2021/olga.jpeg" class="home_team_picture" style="width:150px; height:150px;">
                            <br>
                            <p style="font-weight: 200;">Olga Russakovsky</a>
                        <br>Princeton University</p>
                    </div>

                    <div class="large-1 columns"><p></p></div>
                </div>

                <div class="row">

                    <div class="large-1 columns" style="padding-left:0px">
                        <p></p>
                    </div>

                    <div class="large-2 columns">
                        <a target="_blank" href="http://www.aidanematzadeh.me/"><img src="./static/invited/speakers_2021/aida.jpg" class="home_team_picture" style="width:150px; height:150px;">
                            <br>
                            <p style="font-weight: 200;">Aida Nematzadeh</a>
                        <br>DeepMind</p>
                    </div>

                    <div class="large-2 columns">
                        <a target="_blank" href="https://web.eecs.umich.edu/~justincj/"><img src="./static/invited/speakers_2021/justin.jpg" class="home_team_picture" style="width:150px; height:150px;">
                            <br>
                            <p style="font-weight: 200;">Justin Johnson</a>
                        <br>University of Michigan</p>
                    </div>

                    <div class="large-2 columns">
                        <a target="_blank" href="https://www.damienteney.info/"><img src="./static/invited/speakers_2021/damien.png" class="home_team_picture" style="width:150px; height:150px;">
                            <br>
                            <p style="font-weight: 200;">Damien Teney</a>
                        <br>Idiap Research Institute</p>
                    </div>

                    <div class="large-2 columns">
                        <a target="_blank" href="https://www.cs.unc.edu/~mbansal/"><img src="./static/invited/speakers_2021/mohit.png" class="home_team_picture" style="width:150px; height:150px;">
                            <br>
                            <p style="font-weight: 200;">Mohit Bansal</a>
                        <br>UNC Chapel Hill</p>
                    </div>

                    <div class="large-2 columns">
                        <a target="_blank" href="https://www.cs.cmu.edu/~katef/"><img src="./static/invited/speakers_2021/katerina.png" class="home_team_picture" style="width:150px; height:150px;">
                            <br>
                            <p style="font-weight: 200;">
                                Katerina Fragkiadaki</a>
                        <br>Carnegie Mellon University</p>
                    </div>
                    <div class="large-1 columns">
                        <p></p>
                    </div>
                </div>
                <hr>
            </div> -->
        </div>

        <div class="row" id="program">
            <h1 style="font-size:30px; color:grey; font-weight: 200">Program (TBD)</h1>
            <!-- <br>
            <br>
            <br>

            <h2 style="font-size:25px; color:red; font-weight: 200"><b>Live</b></h2>
            <div id="content">
                <div class="schedule">
                    <table width="100%">
                        <tr id="panel-1">
                            <td width=150>
                                <center>June 19, 2021 <br> 9 AM - 10 AM PT</center>
                            </td>
                            <td width=500>
                                <center>
                                    <img src="./static/invited/speakers_2021/vittorio.png">
                                    <img src="./static/invited/speakers_2021/damien.png">
                                    <img src="./static/invited/speakers_2021/raquel.png">
                                    <br>
                                    <img src="./static/invited/speakers_2021/aida.jpg">
                                    <img src="./static/invited/speakers_2021/olga.jpeg">
                            </td>
                            <td style="padding-left:8px">
                                <b>Panel-1: Future Directions</b>
                                <br>
                                Vittorio Ferrari, Damien Teney, Raquel Fern치ndez, <br> Aida Nematzadeh, Olga Russakovsky
                                <br>
                                <br>
                                Hosted on Zoom, joining link on the internal CVPR website: <a target="_blank" href="https://www.eventscribe.net/2021/2021CVPR/agenda.asp?startdate=6/19/2021&enddate=6/19/2021&BCFO=M&pfp=Workshops&mode=&tn=&cpftwo=&custwo=&pta=/">Link</a>
                                <br><br>
                                <span style="color: grey">(Panel ended) 
                                <br><br>
                                Recording available now: <a target="_blank" href="https://youtu.be/L-86t1AW3z4">[Video]</a>
                                <br>
                                <br>
                                
                                <br>
                                <br>
                            </td>
                        </tr>
                        <tr id="live-qa-1">
                            <td width=150>
                                <center>June 19, 2021 <br>12 PM - 1 PM PT</center>
                            </td>
                            <td width=240>
                                <center>
                                    <img src="./static/invited/poster.png" style="width: 80px; height: 80px; border-radius: 0%;">
                                    <img src="./static/invited/poster.png" style="width: 80px; height: 80px; border-radius: 0%;">
                                    <img src="./static/invited/poster.png" style="width: 80px; height: 80px; border-radius: 0%;">
                                    <br>
                                    <img src="./static/invited/poster.png" style="width: 80px; height: 80px; border-radius: 0%;">
                                    <img src="./static/invited/poster.png" style="width: 80px; height: 80px; border-radius: 0%;">
                                </center>
                            </td>
                            <td style="padding-left:8px"><b>Live QA-1</b>
                                <br>
                                Individual live QA for challenge related talks and poster spotlight presenters.
                                <br>
                                <br>
                                Hosted on Gatherly, joining link on the internal CVPR website: <a target="_blank" href="https://www.eventscribe.net/2021/2021CVPR/agenda.asp?startdate=6/19/2021&enddate=6/19/2021&BCFO=M&pfp=Workshops&mode=&tn=&cpftwo=&custwo=&pta=/">Link</a>
                            </td>
                        </tr>
                        <tr id="panel-2">
                            <td width=150>
                                <center>June 19, 2021 <br>3 PM - 4 PM PT</center>
                            </td>
                            <td width=500>
                                <center>
                                    <img src="./static/invited/speakers_2021/justin.jpg">
                                    <img src="./static/invited/speakers_2021/hehe.jpg">
                                    <img src="./static/invited/speakers_2021/mohit.png">
                                    <br>
                                    <img src="./static/invited/speakers_2021/katerina.png">
                                    <img src="./static/invited/speakers_2021/anirudh.jpeg">
                            </td>
                            <td style="padding-left:8px">
                                <b>Panel-2: Future Directions</b>
                                <br>
                                Justin Johnson, He He, Mohit Bansal,<br> Katerina Fragkiadaki, Anirudh Koul
                                <br>
                                <br>
                                Hosted on Zoom, joining link on the internal CVPR website: <a target="_blank" href="https://www.eventscribe.net/2021/2021CVPR/agenda.asp?startdate=6/19/2021&enddate=6/19/2021&BCFO=M&pfp=Workshops&mode=&tn=&cpftwo=&custwo=&pta=/">Link</a>
                                <br><br>
                                <span style="color: grey">(Panel ended) 
                                <br><br>
                                Recording available now: <a target="_blank" href="https://youtu.be/GobqvKXCVtc">[Video]</a>
                                <br>
                                <br>
                                <br>
                                <br>
                                <br>
                                <br>
                            </td>
                        </tr>
                        <tr id="live-qa-2">
                            <td width=150>
                                <center>June 20, 2021 <br>12 AM - 1 AM PT</center>
                            </td>
                            <td width=240>
                                <center>
                                    <img src="./static/invited/poster.png" style="width: 80px; height: 80px; border-radius: 0%;">
                                    <img src="./static/invited/poster.png" style="width: 80px; height: 80px; border-radius: 0%;">
                                    <img src="./static/invited/poster.png" style="width: 80px; height: 80px; border-radius: 0%;">
                                    <br>
                                    <img src="./static/invited/poster.png" style="width: 80px; height: 80px; border-radius: 0%;">
                                    <img src="./static/invited/poster.png" style="width: 80px; height: 80px; border-radius: 0%;">
                                </center>
                            </td>
                            <td style="padding-left:8px"><b>Live QA-2</b>
                                <br>
                                Individual live QA for challenge related talks and poster spotlight presenters.
                                <br>
                                <br>
                                Hosted on Gatherly, joining link on the internal CVPR website: <a target="_blank" href="https://www.eventscribe.net/2021/2021CVPR/agenda.asp?startdate=6/19/2021&enddate=6/19/2021&BCFO=M&pfp=Workshops&mode=&tn=&cpftwo=&custwo=&pta=/">Link</a>

                            </td>
                        </tr>
                    </table>
                </div> -->
            </div>

            <!-- <br>
            <br>
            <br>

            <h2 style="font-size:25px; color:red; font-weight: 200"><b>Prerecorded</b></h2>
            <div id="content-2">
                <div class="schedule">
                    <table width="100%">
                        <tr>
                            <td width=150>
                                <center> </center>
                            </td>
                            <td width=500>
                                <center><img src="./static/img/aishwarya.jpg"></center>
                            </td>
                            <td style="padding-left:8px"><b>Welcome</b>
                              <br>Aishwarya Agrawal (University of Montreal / Mila / Deepmind)
                              <br><a target="_blank" href="https://youtu.be/boO0dc1zmQY">[Video]</a>
                              <a target="_blank" href="https://drive.google.com/file/d/11mPWEu8fwWMdPeBME3OarcQe2f2TjIxK/view?usp=sharing">[Slides]</a>
                            </td>
                        </tr>

                        <tr>
                            <td width=150>
                                <center>To ask questions, join <a href="#panel-1">Panel-1</a></center>
                            </td>
                            <td width=500>
                                <center><img src="./static/invited/speakers_2021/raquel.png"></center>
                            </td>
                            <td style="padding-left:8px">
                                <b>Invited Talk</b>
                                <br>
                                <b>Title: Visual & Conversational Saliency</b>
                                <br>Raquel Fern치ndez (University of Amsterdam)
                                <br>
                                <a target="_blank" href="https://youtu.be/SNwSukCtPM0">[Video]</a>
                                <a target="_blank" href="https://drive.google.com/file/d/14Vg_zny0Qz2oQjk58WwN6QLBD5sybYd2/view?usp=sharing">[Slides]</a>
                            </td>
                        </tr>
                        <tr>
                            <td width=150>
                                <center>To ask questions, join <a href="#panel-1">Panel-1</a> </center>
                            </td>
                            <td width=500>
                                <center><img src="./static/invited/speakers_2021/vittorio.png"></center>
                            </td>
                            <td style="padding-left:8px">
                                <b>Invited Talk</b>
                                <br>
                                <b>Title: Connecting Vision and Language with Localized Narratives and Open Images</b>
                                <br>Vittorio Ferrari (Google)
                                <br>
                                <a target="_blank" href="https://youtu.be/-iF4gkcdBx0">[Video]</a>
                                <a target="_blank" href="https://drive.google.com/file/d/1SXK223NUXGz-Ayp2mzcBY9mS4W1-snLT/view?usp=sharing">[Slides]</a>
                            </td>
                        </tr>
                        <tr>
                            <td width=150>
                                <center>To ask questions, join <a href="#panel-2">Panel-2</a></center>
                            </td>
                            <td width=500>
                                <center><img src="./static/invited/speakers_2021/hehe.jpg"></center>
                            </td>
                            <td style="padding-left:8px">
                                <b>Invited Talk</b>
                                <br>
                                <b>Title: Towards Overcoming the Language Prior in VQA</b>
                                <br>He He (New York University)
                                <br>
                                <a target="_blank" href="https://youtu.be/C3CAW8fW8A4">[Video]</a>
                                <a target="_blank" href="https://drive.google.com/file/d/1TxqePHlM8Ofa_7aY16QtXQ84jomIkynK/view?usp=sharing">[Slides]</a>
                            </td>
                        </tr>
                        <tr>
                            <td width=150>
                                <center>To ask questions, join <a href="#panel-2">Panel-2</a></center>
                            </td>
                            <td width=500>
                                <center><img src="./static/invited/speakers_2021/anirudh.jpeg"></center>
                            </td>
                            <td style="padding-left:8px">
                                <b>Invited Talk</b>
                                <br>
                                <b>Title: How AI Can Empower The Blind Community</b>
                                <br>Anirudh Koul (Pinterest)
                                <br>
                                <a target="_blank" href="https://youtu.be/zCmzV2QXwMY">[Video]</a>
                                <a target="_blank" href="https://drive.google.com/file/d/1VyOlRsGJNYSNfBnDJE8LSnFyuJNWmyfV/view?usp=sharing">[Slides]</a>
                            </td>
                        </tr>
                        <tr>
                            <td width=150>
                                <center>To ask questions, join <a href="#panel-1">Panel-1</a> </center>
                            </td>
                            <td width=500>
                                <center><img src="./static/invited/speakers_2021/olga.jpeg"></center>
                            </td>
                            <td style="padding-left:8px">
                                <b>Invited Talk</b>
                                <br>
                                <b>Title: Models, metrics, tasks and fairness in vision and language</b>
                                <br>Olga Russakovsky (Princeton University)
                                <br>
                                <a target="_blank" href="https://youtu.be/dyHlSU7HSN8">[Video]</a>
                                <a target="_blank" href="https://drive.google.com/file/d/1QhRQVkqIuGgvtfP61MssHZsM5xXYXs2P/view?usp=sharing">[Slides]</a>
                            </td>
                        </tr>
                        
                        

                        <tr id="vqa-challenge-2021-results">
                            <td width=150>
                                <center>To ask questions, join <a href="#live-qa-1">Live QA-1</a> or <a href="#live-qa-2">Live QA-2</a></center>
                            </td>
                            <td width=500>
                                <center><img src="./static/img/ayush.jpg"></center>
                            </td>
                            <td style="padding-left:8px"><b>VQA Challenge Talk (Overview, Analysis and Winner Announcement)</b>
                                <br>Ayush Shrivastava (Georgia Tech)
                                <br>
                                <a target="_blank" href="https://youtu.be/8RRyaKOlRWs">[Video]</a>
                                <a target="_blank" href="https://drive.google.com/file/d/1ZcA5Bssv4eJPjl32xy17atjnznsbKQjX/view?usp=sharing">[Slides]</a>
                                <br><br>
                                Poster ID: 12
                            </td>
                        </tr>
                        <tr>
                            <td width=150>
                                <center>To ask questions, join <a href="#live-qa-1">Live QA-1</a> or <a href="#live-qa-2">Live QA-2</a></center>
                            </td>
                            <td width=500>
                                <center>
                                    <img src="./static/invited/challenge_2021_winners/MingYan.png">
                                    <img src="./static/invited/challenge_2021_winners/HaiyangXu.png">
                                    <img src="./static/invited/challenge_2021_winners/ChenliangLi.png">
                                    <img src="./static/invited/challenge_2021_winners/JunfengTian.png">
                                    <br>
                                    <img src="./static/invited/challenge_2021_winners/WeiWang.png">
                                    <img src="./static/invited/challenge_2021_winners/BinBi.png">
                                    <img src="./static/invited/challenge_2021_winners/ZhengCao.png">
                                    <img src="./static/invited/challenge_2021_winners/JiZhang.png">
                                    <br>
                                    <img src="./static/invited/challenge_2021_winners/SongfangHuang.png">
                                    <img src="./static/invited/challenge_2021_winners/FeiHuang.png">
                                    <img src="./static/invited/challenge_2021_winners/LuoSi.png">
                                    <br>
                                    <img src="./static/invited/challenge_2021_winners/damo.png" style="border-radius: 0%;">
                                </center>
                            </td>
                            <td style="padding-left:8px"><b>VQA Challenge Winner Talk</b>
                                <br>Team: AliceMind
                                <br>Members:  Ming Yan, Haiyang Xu, Chenliang Li , Junfeng Tian, Wei Wang, Bin Bi, Zheng Cao, Ji Zhang, Songfang Huang, Fei Huang, Luo Si
                                <br>Affiliation: Alibaba Group
                                <br>
                                <a target="_blank" href="https://youtu.be/iRG29Cq4CDE">[Video]</a>
                                <a target="_blank" href="https://drive.google.com/file/d/1KjVjz9cG0KFbEzQwckyDXwrh_63-dbBn/view?usp=sharing">[Slides]</a>
                                <br><br>
                                Poster ID: 13
                            </td>
                        </tr>
                        
                        <tr>
                            <td width=150>
                                <center>To ask questions, join <a href="#live-qa-1">Live QA-1</a> or <a href="#live-qa-2">Live QA-2</a></center>
                            </td>
                            <td width=500>
                                <center><img src="./static/img/yashkant.jpg"></center>
                            </td>
                            <td style="padding-left:8px"><b>TextVQA Challenge Talk (Overview, Analysis and Winner Announcement)</b>
                                <br>Yash Kant (Georgia Tech)
                                <br>
                                <a target="_blank" href="https://youtu.be/0vdMWMStxOA">[Video]</a>
                                <a target="_blank" href="https://drive.google.com/file/d/1CGksfKjJnbsnDV6UnGYaT4_4k1PF-UgK/view?usp=sharing">[Slides]</a>
                                <br><br>
                                Poster ID: 14
                            </td>
                        </tr>
                        <tr>
                            <td width=150>
                                <center>To ask questions, join <a href="#live-qa-1">Live QA-1</a> or <a href="#live-qa-2">Live QA-2</a></center>
                            </td>
                            <td width=500>

                            </td>
                        <td style="padding-left:8px"><b>TextVQA Challenge Winner</b>
                            <br>Members: Yixuan Qiao, Hao Chen, Jun Wang, Xianbin Ye, Ziliang Li, Peng Gao, Guotong Xie
                            <br>
                            <a target="_blank" href="https://drive.google.com/file/d/1TWGJg7q7DJO_wb8dw2KS__pm4lhh7UHn/view">[Paper]</a>
                            <br><br>
                            Poster ID: 15
                        </td>
                        <tr>
                            <td width=150>
                                <center>To ask questions, join <a href="#live-qa-1">Live QA-1</a> or <a href="#live-qa-2">Live QA-2</a></center>
                            </td>
                            <td width=500>
                                <center>
                                    <img src="./static/invited/poster.png" style="width: 80px; height: 80px; border-radius: 0%;">
                                    <img src="./static/invited/poster.png" style="width: 80px; height: 80px; border-radius: 0%;">
                                    <img src="./static/invited/poster.png" style="width: 80px; height: 80px; border-radius: 0%;">
                                </center>
                            </td>
                            <td style="padding-left:8px"><b>Poster Spotlights</b>
                                <br>
                                To watch the poster spotlights, visit: <a href="posters_2021.html">https://visualqa.org/posters_2021</a>.
                            </td>
                        </tr>
                        <tr>
                            <td width=150>
                                <center>To ask questions, join <a href="#live-qa-1">Live QA-1</a> or <a href="#live-qa-2">Live QA-2</a></center>
                            </td>
                            <td width=500>
                                <center><img src="./static/invited/speakers_2020/aman.jpg"></center>
                            </td>
                            <td style="padding-left:8px"><b>TextCaps Challenge Talk (Overview, Analysis and Winner Announcement)</b>
                                <br>Amanpreet Singh (Facebook AI Research)
                                <br>
                                <a target="_blank" href="https://youtu.be/oaPgdb7h4-0">[Video]</a>
                                <a target="_blank" href="https://drive.google.com/file/d/1-llSbeHg3H03e6eHXcRq9urm7nAIDMUG/view?usp=sharing">[Slides]</a>
                                <br><br>
                                Poster ID: 16
                            </td>
                        </tr>
                        <tr>
                            <td width=150>
                                <center>To ask questions, join <a href="#live-qa-1">Live QA-1</a> or <a href="#live-qa-2">Live QA-2</a></center>
                            </td>
                            <td width=500>
                                <center>
                                    <img src="./static/invited/challenge_2021_winners/Picture1.png">
                                    <img src="./static/invited/challenge_2021_winners/Picture2.png">
                                    <img src="./static/invited/challenge_2021_winners/Picture3.png">
                                    <img src="./static/invited/challenge_2021_winners/Picture4.png">
                                    <br>
                                    <img src="./static/invited/challenge_2021_winners/Picture5.png">
                                    <img src="./static/invited/challenge_2021_winners/Picture6.png">
                                    <img src="./static/invited/challenge_2021_winners/Picture7.png">
                                    <img src="./static/invited/challenge_2021_winners/Picture8.png">
                                    <br>
                                    <img src="./static/invited/challenge_2021_winners/Picture9.png">
                                    <img src="./static/invited/challenge_2021_winners/Picture10.png">
                                    <br>
                                    <img src="./static/invited/challenge_2021_winners/Picture11.png" style="border-radius: 0%;">
                                    <img src="./static/invited/challenge_2021_winners/Picture12.png" style="border-radius: 0%;">
                                </center>
                            </td>
                            <td style="padding-left:8px"><b>TextCaps Challenge Winner Talk</b>
                                <br>Members: Zhengyuan Yang, Jianfeng Wang, Xiaowei Hu, Zhe Gan, Lijuan Wang, Yijuan Lu, Dinei Florencio, Cha Zhang, Jiebo Luo, Zicheng Liu
                                <br>Affiliations: Microsoft, University of Rochester
                                <br>
                                <a target="_blank" href="https://youtu.be/IzqS3TUyPh4">[Video]</a>
                                <a target="_blank" href="https://drive.google.com/file/d/1lqIkw0QpNjbQkT_AikcnLZPUSMGLEpsZ/view?usp=sharing">[Slides]</a>
                                <br><br>
                                Poster ID: 17
                            </td>
                        </tr>
                        
                        <tr>
                            <td width=150>
                                <center>To ask questions, join <a href="#panel-1">Panel-1</a></center>
                            </td>
                            <td width=500>
                                <center><img src="./static/invited/speakers_2021/aida.jpg"></center>
                            </td>
                            <td style="padding-left:8px">
                                <b>Invited Talk</b>
                                <br>
                                <b>Title: Towards Better Multimodal Pretraining</b>
                                <br>Aida Nematzadeh (DeepMind)
                                <br>
                                <a target="_blank" href="https://youtu.be/06fSUQw_RCQ">[Video]</a>
                                <a target="_blank" href="https://drive.google.com/file/d/1gG8k_DFtunpDPY4YF0aCCFs3DM5ktc4M/view?usp=sharing">[Slides]</a>
                            </td>
                        </tr>
                        <tr>
                            <td width=150>
                                <center>To ask questions, join <a href="#panel-2">Panel-2</a></center>
                            </td>
                            <td width=500>
                                <center><img src="./static/invited/speakers_2021/justin.jpg"></center>
                            </td>
                            <td style="padding-left:8px">
                                <b>Invited Talk</b>
                                <br>
                                <b>Title: Learning Visual Representations from Language</b>
                                <br>Justin Johnson (University of Michigan)
                                <br>
                                <a target="_blank" href="https://youtu.be/swg0wCRBUJE">[Video]</a>
                                <a target="_blank" href="https://drive.google.com/file/d/1IsR1CH2iK152L9fCvkXAX6a7icKtBXcN/view?usp=sharing">[Slides]</a>
                            </td>
                        </tr>
                        <tr>
                            <td width=150>
                                <center>To ask questions, join <a href="#panel-1">Panel-1</a> </center>
                            </td>
                            <td width=500>
                                <center><img src="./static/invited/speakers_2021/damien.png"></center>
                            </td>
                            <td style="padding-left:8px">
                                <b>Invited Talk</b>
                                <br>
                                <b>Title: Visual question answering and the limits of statistical learning. Are we building a ladder to the moon?</b>
                                <br>Damien Teney (Idiap Research Institute)
                                <br>
                                <a target="_blank" href="https://youtu.be/ggWmvWsE1l0">[Video]</a>
                                <a target="_blank" href="https://drive.google.com/file/d/1qEuN8nFSYdaorG-tujonMqpjQCG59Oro/view?usp=sharing">[Slides]</a>
                            </td>
                        </tr>
                        <tr>
                            <td width=150>
                                <center>To ask questions, join <a href="#panel-2">Panel-2</a></center>
                            </td>
                            <td width=500>
                                <center><img src="./static/invited/speakers_2021/mohit.png"></center>
                            </td>
                            <td style="padding-left:8px">
                                <b>Invited Talk</b>
                                <br>
                                <b>Title: Knowledgeable & Spatial-Temporal Vision+Language</b>
                                <br>Mohit Bansal (UNC Chapel Hill)
                                <br>
                                <a target="_blank" href="https://youtu.be/ckWMwRCNsB4">[Video]</a>
                                <a target="_blank" href="https://drive.google.com/file/d/1JX6NF05DbALR35Ovl2bcc9D-RKglVLKo/view?usp=sharing">[Slides]</a>
                            </td>
                        </tr>
                        <tr>
                            <td width=150>
                                <center>To ask questions, join <a href="#panel-2">Panel-2</a></center>
                            </td>
                            <td width=500>
                                <center><img src="./static/invited/speakers_2021/katerina.png"></center>
                            </td>
                            <td style="padding-left:8px">
                                <b>Invited Talk</b>
                                <br>
                                <b>Title: Augment Machine Intelligence with Multimodal Information</b>
                                <br>Katerina Fragkiadaki (Carnegie Mellon University)
                                <br>
                                <a target="_blank" href="https://youtu.be/uZgU7aOl6ks">[Video]</a>
                                <a target="_blank" href="https://drive.google.com/file/d/1KuqUU_-Y43TZXfBs318MuMqRjMV_Coap/view?usp=sharing">[Slides]</a>
                            </td>
                        </tr>
                        <tr>
                            <td width=150>
                                <center> </center>
                            </td>
                            <td width=500>
                                <center><img src="./static/img/aishwarya.jpg"></center>
                            </td>
                            <td style="padding-left:8px"><b>Closing Remarks</b>
                              <br>Aishwarya Agrawal (University of Montreal / Mila / Deepmind)
                              <br>
                              <a target="_blank" href="https://youtu.be/wjCjG_kkIU4">[Video]</a>
                              <a target="_blank" href="https://drive.google.com/file/d/1sLZyDsEuFa23D8Z-qCq7JLG_USMMR2es/view?usp=sharing">[Slides]</a>
                            </td>
                        </tr>
                    </table>
                </div>
                <hr>
            </div>
        </div> -->

        <!-- <div class="row" id="sub">
            <h1 style="font-size:30px; color:grey; font-weight: 200">Submission Instructions</h1>
            <div class="large-12 columns" style="text-align:left;">
                <p style="font-size:15px; font-weight: 400; text-align:left">We invite submissions of extended abstracts of at most 2 pages (excluding references) describing work in areas such as: Visual Question Answering, Visual Dialog, (Textual) Question Answering, (Textual) Dialog Systems, Commonsense knowledge, Video Question Answering, Video Dialog, Vision + Language, and Vision + Language + Action (Embodied Agents). Accepted submissions will be presented as posters at the workshop. The extended abstract should follow the CVPR formatting guidelines and be emailed as a single PDF to the <a href="#submit">email id</a> mentioned below.
                </p>
                <br>

                <ul style="font-size:15px;">
                    <span style="font-size:20px;">Dual Submissions</span><br>
                    We encourage submissions of relevant work that has been previously published, or is to be presented at the main conference. The accepted abstracts will not appear in the official IEEE proceedings.
                    <br><br>

                    <span style="font-size:20px;" id="submit">Where to Submit?</span><br>
                    Please send your abstracts to <a href="mailto:visualqa.workshop@gmail.com">visualqa.workshop@gmail.com</a>
                    <br><br>
            </div>
            <hr>
        </div> -->
<!--  -->
        <hr>


        <!-- <div class="row">
            <h1 style="font-size:30px; color:grey; font-weight: 200">Workshop Organizers</h1>
            <div class="team" id="people">
                <div class="row">
                    <div class="large-2 columns">
                        <a href="https://pzzhang.github.io/pzzhang/"><img src="./static/eccv2022/img/pengchuan-circle.jpg" class="home_team_picture style=" width="75" height="75" ;>
                            <br><br>
                        </a>
                        <p style="font-size:12px; font-weight: 200;">Pengchuan Zhang
                            <br>Meta AI</p>
                    </div>
                    <div class="large-2 columns">
                        <a href="https://chunyuan.li/"><img src="https://vlp-tutorial.github.io/2022/img/organizer/chunyuan.jpg" class="home_team_picture style=" width="75" height="75" ;>
                            <br><br>
                        </a>
                        <p style="font-size:12px; font-weight: 200;">Chunyuan Li
                            <br>Microsoft</p>
                    </div>
                    <div class="large-2 columns">
                        <a href="http://jyotianeja.com/""><img src="https://scholar.googleusercontent.com/citations?view_op=view_photo&user=FYB92lkAAAAJ&citpid=1" class="home_team_picture style=" width="75" height="75" ;>
                            <br><br>
                        </a>
                        <p style="font-size:12px; font-weight: 200;">Jyoti Aneja
                            <br>Microsoft</p>
                    </div>
                    <div class="large-2 columns">
                        <a href="https://www.linkedin.com/in/pingjin1"><img src="./static/eccv2022/img/ping_jin.jpeg" class="home_team_picture style=" width="75" height="75" ;>
                            <br><br>
                        </a>
                        <p style="font-size:12px; font-weight: 200;">Ping Jin
                            <br>Microsoft</p>
                    </div>

                    <div class="large-2 columns">
                        <a href="https://jwyang.github.io"><img src="https://jwyang.github.io/images/profile.png" target="_blank" class="home_team_picture style=" width="75" height="75" ;>
                            <br><br>
                        </a>
                        <p style="font-size:12px; font-weight: 200;">Jianwei Yang
                            <br>Microsoft</p>
                        </div>
                    <div class="large-2 columns">
                            <a href="https://xinw.ai/"><img src="https://xinw.ai/assets/images/photo.JPG" class="home_team_picture style=" width="75" height="75" ;>
                                <br><br>
                            </a>
                            <p style="font-size:12px; font-weight: 200;">Xin Wang
                                <br>Microsoft</p>
                    </div>
                <div class="row">
                    <div class="large-1 columns">
                        <p></p>
                    </div>
                    <div class="large-1 columns">
                        <p></p>
                    </div>

                    <div class="large-2 columns">
                        <a href="https://www.linkedin.com/in/houdong-hu-08334227"><img src="./static/eccv2022/img/Houdong_profile.png" target="_blank" class="home_team_picture style=" width="75" height="75" ;>
                            <br><br>
                        </a>
                        <p style="font-size:12px; font-weight: 200;">Houdong Hu
                            <br>Microsoft</p>
                    </div>
                    <div class="large-2 columns">
                        <a href="https://www.microsoft.com/en-us/research/people/zliu/"><img src="https://www.microsoft.com/en-us/research/wp-content/uploads/2017/03/avatar_user__1490216903-360x360.jpg" target="_blank" class="home_team_picture style=" width="75" height="75" ;>
                            <br><br>
                        </a>
                        <p style="font-size:12px; font-weight: 200;">Zicheng Liu
                            <br>Microsoft</p>
                    </div>
                    <div class="large-2 columns">
                        <a href="https://hliu.cc/"><img src="./static/eccv2022/img/haotian-circle.jpg" class="home_team_picture style=" width="75" height="75" ;>
                            <br><br>
                        </a>
                        <p style="font-size:12px; font-weight: 200;">Haotian Liu
                            <br>Univ. of Wisconsin at Madison</p>
                    </div>
                    <div class="large-2 columns">
                        <a href="https://liunian-harold-li.github.io/"><img src="https://liunian-harold-li.github.io/img/harold_cropped.jpeg" class="home_team_picture style=" width="75" height="75" ;>
                            <br><br>
                        </a>
                        <p style="font-size:12px; font-weight: 200;">Liunian Li
                            <br>UCLA</p>
                    </div>
                    <div class="large-2 columns">
                        <a href="http://web.cs.ucla.edu/~kwchang"><img src="./static/eccv2022/img/kaiwei-circle.jpg" class="home_team_picture style=" width="75" height="75" ;>
                            <br><br>
                        </a>
                        <p style="font-size:12px; font-weight: 200;">Kai-Wei Chang
                            <br>UCLA</p>
                    </div>
                    <div class="large-2 columns">
                        <a href="https://www.microsoft.com/en-us/research/people/jfgao/"><img src="https://www.microsoft.com/en-us/research/uploads/prod/2020/09/20191101_170350330_iOS-4.jpg" class="home_team_picture style=" width="75" height="75" ;>
                            <br><br>
                        </a>
                        <p style="font-size:12px; font-weight: 200;">Jianfeng Gao
                            <br>Microsoft</p>
                    </div>    
                </div>
            <hr>
            </div>
        </div> -->
<div class="row">
    <h1 style="font-size:30px; color:grey; font-weight: 200">Workshop Organizers</h1>
    <div class="team" id="people">
        <div class="row">
            <!-- <div class="large-1 columns">
                <p></p>
            </div>
            <div class="large-1 columns">
                <p></p>
            </div> -->
            <div class="large-1 columns">
                <a href="https://pzzhang.github.io/pzzhang/"><img src="./static/eccv2022/img/pengchuan-circle.jpg" class="home_team_picture style=" width="75" height="75" ;>
                    <br><br>
                </a>
                <p style="font-size:12px; font-weight: 200;">Pengchuan Zhang
                    <br>Meta AI</p>
            </div>
            <div class="large-1 columns">
                <a href="https://chunyuan.li/"><img src="https://vlp-tutorial.github.io/2022/img/organizer/chunyuan.jpg" class="home_team_picture style=" width="75" height="75" ;>
                    <br><br>
                </a>
                <p style="font-size:12px; font-weight: 200;">Chunyuan Li
                    <br>Microsoft</p>
            </div>
            <div class="large-1 columns">
                <a href="http://jyotianeja.com/"><img src="https://scholar.googleusercontent.com/citations?view_op=view_photo&user=FYB92lkAAAAJ&citpid=1" class="home_team_picture style=" width="75" height="75" ;>
                    <br><br>
                </a>
                <p style="font-size:12px; font-weight: 200;">Jyoti Aneja
                    <br>Microsoft</p>
            </div>
            <div class="large-1 columns">
                <a href="https://www.linkedin.com/in/pingjin1"><img src="./static/eccv2022/img/ping_jin.jpeg" class="home_team_picture style=" width="75" height="75" ;>
                    <br><br>
                </a>
                <p style="font-size:12px; font-weight: 200;">Ping Jin
                    <br>Microsoft</p>
            </div>

            <div class="large-1 columns">
                <a href="https://jwyang.github.io"><img src="https://jwyang.github.io/images/profile.png" target="_blank" class="home_team_picture style=" width="75" height="75" ;>
                    <br><br>
                </a>
                <p style="font-size:12px; font-weight: 200;">Jianwei Yang
                    <br>Microsoft</p>
                </div>
            <div class="large-1 columns">
                    <a href="https://xinw.ai/"><img src="https://xinw.ai/assets/images/photo.JPG" class="home_team_picture style=" width="75" height="75" ;>
                        <br><br>
                    </a>
                    <p style="font-size:12px; font-weight: 200;">Xin Wang
                        <br>Microsoft</p>
            </div>
        <!--  -->

            <div class="large-1 columns">
                <a href="https://hliu.cc/"><img src="./static/eccv2022/img/haotian-circle.jpg" class="home_team_picture style=" width="75" height="75" ;>
                    <br><br>
                </a>
                <p style="font-size:12px; font-weight: 200;">Haotian Liu
                    <br>UW Madison</p>
            </div>
            <div class="large-1 columns">
                <a href="https://liunian-harold-li.github.io/"><img src="https://liunian-harold-li.github.io/img/harold_cropped.jpeg" class="home_team_picture style=" width="75" height="75" ;>
                    <br><br>
                </a>
                <p style="font-size:12px; font-weight: 200;">Liunian Li
                    <br>UCLA</p>
            </div>
            <!-- <div class="row">
            </div> -->
                <div class="large-1 columns">
                    <a href="https://scholar.google.com/citations?hl=zh-CN&user=1vz0kKUAAAAJ&view_op=list_works&sortby=pubdate"><img src="https://media-exp1.licdn.com/dms/image/C5603AQHrGMQQiwJC7w/profile-displayphoto-shrink_400_400/0/1561582656147?e=1663804800&v=beta&t=j7gTbLwYa8oNcpZecCUW841a3Z7J7Ogd0XyTL0qAYYA" class="home_team_picture style=" width="75" height="75" ;>
                        <br><br>
                    </a>
                    <p style="font-size:12px; font-weight: 200;">Haotian Zhang  
                        <br>University of Washington</p>
                </div> 
                <div class="large-1 columns">
                    <a href="https://www.linkedin.com/in/shohei-ono-ab7404a8/"><img src="./static/eccv2022/img/shohei.png" class="home_team_picture style=" width="75" height="75" ;>
                        <br><br>
                    </a>
                    <p style="font-size:12px; font-weight: 200;">Shohei Ono 
                        <br>Microsoft</p>
                </div> 
        <!-- </div> -->
    <hr>
</div>
</div>
<!-- Challenge Organizers -->
<div class="row">
    <h1 style="font-size:30px; color:grey; font-weight: 200">Challenge Organizers (TBD)</h1>
    <div class="team" id="people">
        <div class="row">
            <div class="large-1 columns">
                <a href="https://sites.google.com/site/yinfeiyang"><img src="https://media-exp1.licdn.com/dms/image/C5603AQHW7bZV8zHTOg/profile-displayphoto-shrink_400_400/0/1516627614880?e=1663804800&v=beta&t=ds7yiDBs7Y6QnPh3WdYs3Ld_DElsqg4hyntWaFjvQGE" target="_blank" class="home_team_picture style=" width="75" height="75" ;>
                    <br><br>
                </a>
                <p style="font-size:12px; font-weight: 200;">Yinfei Yang 
                    <br>Apple</p>
            </div>
            <!-- <div class="large-1 columns">
                <a href="https://www.linkedin.com/in/chao-jia-6157ba14/ "><img src="https://scholar.googleusercontent.com/citations?view_op=medium_photo&user=VCgDrQsAAAAJ&citpid=3" class="home_team_picture style=" width="75" height="75" ;>
                    <br><br>
                </a>
                <p style="font-size:12px; font-weight: 200;">Chao Jia
                    <br>Waymo</p>
            </div> -->
            <div class="large-1 columns">
                <a href="https://www.linkedin.com/in/yi-ting-chen-google/ "><img src="https://media-exp1.licdn.com/dms/image/C5603AQEVUanerXnP6Q/profile-displayphoto-shrink_400_400/0/1655777497160?e=1663804800&v=beta&t=rUyQTbYbJsDX65VFP7LgVlr63TG_TkgA4fW0ZtHrkeA" class="home_team_picture style=" width="75" height="75" ;>
                    <br><br>
                </a>
                <p style="font-size:12px; font-weight: 200;">Yi-Ting Chen 
                    <br>Google</p>
            </div>
            <div class="large-1 columns">
                <a href="https://www.linkedin.com/in/ye-xia-19b46b42/ "><img src="https://scholar.googleusercontent.com/citations?view_op=medium_photo&user=QQhJ1pAAAAAJ&citpid=1" class="home_team_picture style=" width="75" height="75" ;>
                    <br><br>
                </a>
                <p style="font-size:12px; font-weight: 200;">Ye Xia 
                    <br>Google</p>
            </div>

            <div class="large-1 columns">
                <a href="https://openreview.net/profile?id=~Yangguang_Li1 "><img src="./static/eccv2022/img/YangguangLi.png" target="_blank" class="home_team_picture style=" width="75" height="75" ;>
                    <br><br>
                </a>
                <p style="font-size:12px; font-weight: 200;">Yangguang Li 
                    <br>Sensetime</p>
                </div>
            <div class="large-1 columns">
                    <a href="https://jeff-liangf.github.io"><img src="https://media-exp1.licdn.com/dms/image/C5603AQEMlx42TO8RFw/profile-displayphoto-shrink_400_400/0/1618561979511?e=1663804800&v=beta&t=MTMEQbrytIkkvxrMD87gpbNo4o0wNir_5Xu7_Bs9jxk" class="home_team_picture style=" width="75" height="75" ;>
                        <br><br>
                    </a>
                    <p style="font-size:12px; font-weight: 200;">Feng Liang 
                        <br>UT Austin</p>
            </div>
            <div class="large-1 columns">
                <a href="https://slothercui.github.io/ "><img src="./static/eccv2022/img/YufengCui.png" target="_blank" class="home_team_picture style=" width="75" height="75" ;>
                    <br><br>
                </a>
                <p style="font-size:12px; font-weight: 200;">Yufeng Cui 
                    <br>Sensetime</p>
            </div>
            <div class="large-1 columns">
                <a href="https://ksaito-ut.github.io/ "><img src="https://ksaito-ut.github.io/images/image_ksaito.jpeg " target="_blank" class="home_team_picture style=" width="75" height="75" ;>
                    <br><br>
                </a>
                <p style="font-size:12px; font-weight: 200;">Kunaiki Saito 
                    <br>Google</p>
            </div>
            <div class="large-1 columns">
                <a href="https://sites.google.com/site/kihyuksml/ "><img src="./static/eccv2022/img/KihyukSohn.jpeg" class="home_team_picture style=" width="75" height="75" ;>
                    <br><br>
                </a>
                <p style="font-size:12px; font-weight: 200;">Kihyuk Sohn 
                    <br>Google</p>
            </div>
            <div class="large-1 columns">
                <a href="https://www.linkedin.com/in/zhangxiangxiao/ "><img src="https://media-exp1.licdn.com/dms/image/C5603AQEq333rtuTR_g/profile-displayphoto-shrink_400_400/0/1517520796402?e=1663804800&v=beta&t=pBCemT-zu6y6YzXnKkPTnjMJYvrUJ5izmyH6mGhNC1o" class="home_team_picture style=" width="75" height="75" ;>
                    <br><br>
                </a>
                <p style="font-size:12px; font-weight: 200;">Xiang Zhang 
                    <br>Google</p>
            </div>
            <div class="large-1 columns">
                <a href="https://chunliangli.github.io"><img src="https://media-exp1.licdn.com/dms/image/C4E03AQG3kOloptyXaw/profile-displayphoto-shrink_400_400/0/1516885291151?e=1663804800&v=beta&t=7tGy9QRO0P55ntCKTHha72WtJQQ2CWHk2gh0Usa9c-I" class="home_team_picture style=" width="75" height="75" ;>
                    <br><br>
                </a>
                <p style="font-size:12px; font-weight: 200;">Chun-Liang Li
                    <br>Google</p>
            </div>  
            <!-- <div class="row"> -->
            <!-- </div> -->
                <div class="large-1 columns">
                    <a href="https://chl260.github.io/"><img src="https://media-exp1.licdn.com/dms/image/C5603AQGFEybThH2fnQ/profile-displayphoto-shrink_400_400/0/1518764142934?e=1663804800&v=beta&t=3Ayn4myRNADLf1a0R2hKSP3QfhL8FDyELJvHsfxyKc4 " class="home_team_picture style=" width="75" height="75" ;>
                        <br><br>
                    </a>
                    <p style="font-size:12px; font-weight: 200;">Chen-Yu Lee 
                        <br>Google</p>
                </div>
                 <div class="large-1 columns">
                    <a href="https://houwenpeng.com/"><img src="https://www.microsoft.com/en-us/research/uploads/prod/2019/07/Houwen_Peng_360x360-5d1ce02ab189f.jpg" class="home_team_picture style=" width="75" height="75" ;>
                        <br><br>
                    </a>
                    <p style="font-size:12px; font-weight: 200;">Houwen Peng
                        <br>MSRA</p>
                </div>
                <!--
                <div class="large-1 columns">
                    <a href="https://chunliangli.github.io"><img src="https://media-exp1.licdn.com/dms/image/C4E03AQG3kOloptyXaw/profile-displayphoto-shrink_400_400/0/1516885291151?e=1663804800&v=beta&t=7tGy9QRO0P55ntCKTHha72WtJQQ2CWHk2gh0Usa9c-I" class="home_team_picture style=" width="75" height="75" ;>
                        <br><br>
                    </a>
                    <p style="font-size:12px; font-weight: 200;">Chun-Liang Li
                        <br>Google</p> -->
                </div>
        </div>
    <hr>    
</div>




<div class="row">
    <h1 style="font-size:30px; color:grey; font-weight: 200">Advisory Committee</h1>
    <div class="team" id="people">
        <div class="row">
            <!-- <div class="large-1 columns">
                <p></p>
            </div>
            <div class="large-1 columns">
                <p></p>
            </div> -->
            <div class="large-1 columns">
                <a href="https://people.eecs.berkeley.edu/~trevor/"><img src="https://www2.eecs.berkeley.edu/Faculty/Photos/Fullsize/darrell.jpg" target="_blank" class="home_team_picture style=" width="75" height="75" ;>
                    <br><br>
                </a>
                <p style="font-size:12px; font-weight: 200;">Trevor Darrell
                    <br>UC Berkley</p>
            </div>
            <div class="large-1 columns">
                <a href="https://www.leizhang.org/"><img src="./static/eccv2022/img/leizhang-circle.jpg" target="_blank" class="home_team_picture style=" width="75" height="75" ;>
                    <br><br>
                </a>
                <p style="font-size:12px; font-weight: 200;">Lei Zhang
                    <br>IDEA</p>
            </div>
            <div class="large-1 columns">
                <a href="https://people.ece.uw.edu/hwang/"><img src="./static/eccv2022/img/hwang-circle.jpg" target="_blank" class="home_team_picture style=" width="70" height="70" ;>
                    <br><br>
                </a>
                <p style="font-size:12px; font-weight: 200;">Jenq-Neng Hwang
                    <br>University of Washington</p>
            </div>
            
            
            <div class="large-1 columns">
                <a href="https://pages.cs.wisc.edu/~yongjaelee/"><img src="./static/eccv2022/img/lee-circle.jpg"" target="_blank" class="home_team_picture style=" width="75" height="75"  ;>
                    <br><br>
                </a>
                <p style="font-size:12px; font-weight: 200;">Yong Jae Lee
                    <br>UW Madison</p>
            </div>
            <!-- <div class="large-1 columns">
                <p></p>
            </div>
            <div class="large-1 columns">
                <p></p>
            </div>
        </div>

        <div class="row" style="padding-left: 1em; padding-right: 1em;">
            <div class="large-1 columns" style="padding-left:75px">
              <p></p>
            </div>
            <div class="large-1 columns">
                <p></p>
            </div>
            <div class="large-1 columns">
                <p></p>
            </div> -->
            <div class="large-1 columns">
                <a href="https://www.linkedin.com/in/houdong-hu-08334227"><img src="./static/eccv2022/img/Houdong_profile.png" target="_blank" class="home_team_picture style=" width="75" height="75" ;>
                    <br><br>
                </a>
                <p style="font-size:12px; font-weight: 200;">Houdong Hu
                    <br>Microsoft</p>
            </div>
            <div class="large-1 columns">
                <a href="https://www.microsoft.com/en-us/research/people/zliu/"><img src="https://www.microsoft.com/en-us/research/wp-content/uploads/2017/03/avatar_user__1490216903-360x360.jpg" target="_blank" class="home_team_picture style=" width="75" height="75" ;>
                    <br><br>
                </a>
                <p style="font-size:12px; font-weight: 200;">Zicheng Liu
                    <br>Microsoft</p>
            </div>
            <div class="large-1 columns">
                <a href="http://people.csail.mit.edu/celiu/"><img src="https://scholar.googleusercontent.com/citations?view_op=view_photo&user=j7MW4iYAAAAJ&citpid=8" target="_blank" class="home_team_picture style=" width="75" height="75" ;>
                    <br><br>
                </a>
                <p style="font-size:12px; font-weight: 200;">Ce Liu
                    <br>Microsoft</p>
            </div>

            <div class="large-1 columns">
                <a href="https://www.microsoft.com/en-us/research/people/xdh/"><img src="./static/eccv2022/img/xuedong-circle.jpg" target="_blank" class="home_team_picture style=" width="75" height="75" ;>
                    <br><br>
                </a>
                <p style="font-size:12px; font-weight: 200;">Xuedong Huang
                    <br>Microsoft</p>
            </div>
            <div class="large-1 columns">
                <a href="http://web.cs.ucla.edu/~kwchang"><img src="./static/eccv2022/img/kaiwei-circle.jpg" class="home_team_picture style=" width="75" height="75" ;>
                    <br><br>
                </a>
                <p style="font-size:12px; font-weight: 200;">Kai-Wei Chang
                    <br>UCLA</p>
            </div>
            <div class="large-1 columns">
                <a href="https://www.microsoft.com/en-us/research/people/jfgao/"><img src="https://www.microsoft.com/en-us/research/uploads/prod/2020/09/20191101_170350330_iOS-4.jpg" class="home_team_picture style=" width="75" height="75" ;>
                    <br><br>
                </a>
                <p style="font-size:12px; font-weight: 200;">Jianfeng Gao
                    <br>Microsoft</p>
            </div>                       
            <hr>
        </div>
    </div>
</div>

        <!-- Contact Information -->
        <div class="large-12 columns" style="background: white;">
            <p style="color:black; text-align:center; display:block; margin-top:7px;">Workshop and Challenge Questions?
                <br>
                Reach out: <a href="https://github.com/Computer-Vision-in-the-Wild/eccv-2022" target="_top">https://github.com/Computer-Vision-in-the-Wild/eccv-2022</a>
                <br>
                Workshop Organizing Team
            </p>
        </div>
    </section>
    <script>
    $(document).foundation();
    </script>
    <script>
    (function(i, s, o, g, r, a, m) {
        i['GoogleAnalyticsObject'] = r;
        i[r] = i[r] || function() {
            (i[r].q = i[r].q || []).push(arguments)
        }, i[r].l = 1 * new Date();
        a = s.createElement(o),
            m = s.getElementsByTagName(o)[0];
        a.async = 1;
        a.src = g;
        m.parentNode.insertBefore(a, m)
    })(window, document, 'script', '//www.google-analytics.com/analytics.js', 'ga');

    ga('create', 'UA-63638588-1', 'auto');
    ga('send', 'pageview');
    </script>
    <!-- jquery smooth scroll to id's -->
    <script>
    $(function() {
        $('a[href*=#]:not([href=#])').click(function() {
            if (location.pathname.replace(/^\//, '') == this.pathname.replace(/^\//, '') && location.hostname == this.hostname) {
                var target = $(this.hash);
                target = target.length ? target : $('[name=' + this.hash.slice(1) + ']');
                if (target.length) {
                    $('html,body').animate({
                        scrollTop: target.offset().top
                    }, 1000);
                    return false;
                }
            }
        });
    });
    </script>
</body>

</html>
